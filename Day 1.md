# Day 1

## 学习常用的网络结构：

### 1.残差网络：

在深层卷积神经网络中，梯度优化更困难，残差网络将输入值x经过权重层和激活函数得到的结果与原来的x的值相加，在经过一个激活函数得到输出结果，解决了难以训练的问题，提高训练速度。具体有两种方式：

![image-20220629122704349](C:\Users\19127\AppData\Roaming\Typora\typora-user-images\image-20220629122704349.png)

左图对应输入通道为64时，用两个(3,3)的卷积，中间不改变通道数，最后**相加激活**得到输出。右图对应于输入通道为256时，先用一个(1,1)的卷积把**通道数缩小为1/4**，然后在这个通道数上进行(3,3)的卷积，最后再经过一个(1,1)的卷积改为原通道，然后**相加激活**的到输出。

**ResNet34中使用的是左图的残差结构，ResNet50/101/152使用的是右图的残差结构。**

### 2.深度可分离卷积：

在**轻量化的卷积网络**中应用广泛。它的结构如下图：

![image-20220629123205219](C:\Users\19127\AppData\Roaming\Typora\typora-user-images\image-20220629123205219.png)

对于一个输入矩阵，我先用一个(3,3)的卷积，各个通道**不相加**，这个过程其实就是**分组卷积**，**分组的个数等于输入通道数**，之后再用(1,1)的卷积改变**输出通道数**。

深度可分离卷积**极大地降低了卷积的参数量**。

### 3.SE注意力机制：

**SE注意力机制**希望模型可以**自动学习到不同channel特征的重要程度**，因为很显然各个通道间**所包含特征的重要程度是不一样的**。它的结构如下：

![image-20220629123820679](C:\Users\19127\AppData\Roaming\Typora\typora-user-images\image-20220629123820679.png)

通过一个**全局平均池化**，将输入的大小压缩成1*1，通道数不变，对这个一维矩阵做激励，得到的这样的一个一维矩阵相当于是各个通道的权重，将这个一维矩阵与原输入相乘，得到一个重要成不同的输出，这样就区分出了各个通道的重要性。

原始SE注意力机制的**压缩**和**激励**如下：

![image-20220629124755627](C:\Users\19127\AppData\Roaming\Typora\typora-user-images\image-20220629124755627.png)

对**ResNet**和**MobileNet**使用**注意力机制**：

![image-20220629130544659](C:\Users\19127\AppData\Roaming\Typora\typora-user-images\image-20220629130544659.png)

**ResNet**中的**SE注意力机制**放在了(1,1)卷积之后，激励部分使用的是**全连接层**。MobileNetV3中**SE注意力机制**放在了(1,1)卷积之前，并且激励部分使用的是**卷积层**。



------



## 论文泛读——方面级情感三元组的分析：

抽取方面词、观点词、关联情感--->跨域共享联合抽取(从句子中端到端提取aspect情感三元组)

### 1.跨域共享联合抽取（SSJE）：

首先利用基编码器学习单词级表示，并利用图卷积网络在句子的句法依存树上获取单词的依存信息，融合到跨度表示中；然后，列举并过滤句子中所有可能的跨度，生成候选跨度，这些候选跨度可以作为方面词和观点词共享；最后，将两个分别作为方面词和观点词的候选词及其对应的局部上下文输入分类器，一次性生成情感三元组。

### 2.GCN（图卷积神经网络）

解决图结构数据，不同于CNN、RNN模型，但是和CNN的本质一样，都是特征提取器，只不过他的对象是图数据。GCN用这些特征进行节点分类，图分类，边预测。

什么结构：有N个节点的N*D维节点特征组成的矩阵X和   各个节点之间的关系N * N维的矩阵A加上单位矩阵I在进行归一化    相乘，加上一个权重，再激活一下。

**即使不训练，完全使用随机初始化的参数W，GCN提取出来的特征就以及十分优秀了！**这跟CNN不训练是完全不一样的，后者不训练是根本得不到什么有效特征的。



# Day 2

MobilenetV3轻量级网络。

主要结构：

1.深度可分离卷积

2.SE注意力机制、

3.新型的激活函数：Hardswish激活函数

![](C:\Users\19127\AppData\Roaming\Typora\typora-user-images\image-20220630183931997.png)

Hardswish函数在梯度上存在突变，对于训练的精度不利，但是在深层网络中影响较小，所以可以在浅层网络中可以用Relu函数代替。

4.修改网络结构：缩减卷积层并没有减少太多精度

![image-20220702123331510](C:\Users\19127\AppData\Roaming\Typora\typora-user-images\image-20220702123331510.png)

# Day 3

YOLOv3网络学习笔记

v3是anchor based算法，预先在图片上生成很多先验框，然后通过神经网络去判断放的框内有没有我们想要的特征物体，如果有，就用神经网络对先验框的中心和长和宽进行调整，最终输出物体的长和宽。

**YOLOv3**的网络有**三个输出**，对于输入为(3,416,416)的图片，通过这个网络之后会输出(75,13,13)，(75,26,26)，(75,52,52)，分别对应有13×13、26×26、52×52的不同大小网格的三张图片，图像分成了**多个网格**，每个网格上都会放置好**3个先验框**，先验框的**长宽是一开始就固定的**，**13×13的网格用于检测大物体，26×26的网格用于检测中等物体，52×52的网格用于检测小物体**。一共有**13×13×3+26×26×3+52×52×3**个框。**物体中心点落在哪个框内，这个框就负责识别这个物体。**

**75的含义是3×(num_class+4+1)**，这是对应**voc**数据集，有**20**个类别。**20指的是20个类别的概率**，**4指对先验框的中心点和长宽的修正量，1指这个框内有没有物体。**因为每个格子都有**3个先验框**，所以再乘3。如果使用**coco数据集**，有80个类别，那么对应的维度就是**3×(80+4+1)=255**。

## 整体网络：

分为三部分，分别为backbone（主体）,neck（脖子）和head（头部）。

<img src="C:\Users\19127\AppData\Roaming\Typora\typora-user-images\image-20220702145221218.png" alt="image-20220702145221218" style="zoom:67%;" />

## backbone部分：

为DarkNet53，称为特征提取网络，和分类网络基本一致，这部分是通用的（可以做分类任务）

总体形式如下：

![image-20220702150614059](C:\Users\19127\AppData\Roaming\Typora\typora-user-images\image-20220702150614059.png) 

​		先通过卷积层把输入通道数扩充到32，然后接着很多个Residual Block,中间穿插很多向下采样（Conv）。Residual Block包含两个卷积归一化层，第一个卷积归一化层就是通过1 * 1的卷积把输入通道数降到一半，然后经过归一化和激活函数；第二个卷积层主要用来提取特征，大小为3 *3，再将输出矩阵的通道数与输入通道数改为一致，然后经过归一化和激活函数后将输入与输出相加（残差结构）得到输出结果，此结果也是下一个卷积归一化的输入。可见DarkNet53借鉴了残差结构，残差结构用于深度比较深的网络可以防止梯度爆炸或梯度消失。

​		YOLO v3有三个输出，决定了head有三个输出，则DarkNet53也得有三个输出（上图中的Output Feature），这三个输出结果会输入到neck中。



## Neck部分：

使用的是**FPN**，这一部分也叫**特征金字塔**，它的作用是将**多尺度的出入进行特征融合**。

### 整体结构：

**backbone**部分输出的shape分别为（13，13，1024），（26，26，512），（52，52，256）。将这三个输出分别输入到FPN中，（13，13，1024）这一个输入，**经过5次卷积后**，输出（13，13，512），然后**兵分两路**，一路传入到**head**中，一路再经过**一个卷积和上采样**，得到（26，26，256），将这个输出和**backbone**的第2个输出也就是（26，26，512）**堆叠**（**concat**）,得到（26，26，768）。

（堆叠：大小不变，通道数相加）

卷积池化使得图像**大小越来越小**，这个过程叫**下采样**。**上采样就是通过插值的方法，扩充图像大小**，就像这边的（13，13）变成（26，26）。

**concat**操作是把两个矩阵**堆叠**到一起，里面的数不变，只是单纯的堆叠，**shape等于两个相加**。残差结构中的**add**区分开，相加操作需要**两个输入shape一致，里面的数也会相加**。

后续部分其实就是第一种操作的重复。堆叠后的矩阵，经过5次卷积，再兵分两路，一路输入head，一路经过卷积上采样，和backbone第一个输出堆叠。最后通过五次卷积，输入到head中。

解释图:

![image-20220702192347205](C:\Users\19127\AppData\Roaming\Typora\typora-user-images\image-20220702192347205.png)

获得到网络输出的三个矩阵后，并不是**直接获得了我们最后的预测框**。我们之前说过对于voc数据集，75=3×（20+4+1），其中20和1都是和分类相关的，对于这个4，也就是对先验框的4个调整的参数，通过调整后也就输出了最后的预测框。

先验框是**固定不变的**，每个特征图，每个图的**每个格子有3个先验框**，所以预先准备**9个大小的先验框**。

anchors大小：[116,90],[156,198],[373,326],[30,61],[62,45],[59,119],[10,13],[16,30],[33,23]，这些大小是**相对于416×416的尺寸**，我们最后三个输出的大小为13×13，26×26，52×52，所以要进行**相应的缩放**。

我们以13×13的输出为例，原本416×416大小变成13×13，相当于缩小了**32倍**，也就是说**原图32×32个小方块对应于最后输出的1×1的像素点**。anchors[116,90],[156,198],[373,326]相应地长宽都应该**除以32**，这就是**13×13每个点上的三个先验框**。

![image-20220702195440234](C:\Users\19127\AppData\Roaming\Typora\typora-user-images\image-20220702195440234.png)

**粉红色**的就是对应到13×13上的**先验框**，它是我们一开始自己就确定的，显然是**不正确**，需要模型对它调整。

先验框怎么摆放的呢，它的中心就是落在**13×13的交点**上，长宽就是除以32的结果。先验框坐标记为（cx,cy,pw,ph），模型输出的4为（tx,ty,tw,th）,调整的公式如上图所示，中心点取**sigmoid激活函数**，**sigmoid函数范围是0-1**，也就是中心点的调整范围永远在**右下角的框内**，这也就是我们说的，**物体的中心落在哪个格子里，就有哪个框负责预测**。

**长宽取exp后相乘**。这就得到了在13×13尺寸图上的预测框，然后**再乘以32缩放回来就得到了最后的预测框**。



# Day 4

Ai studio 使用教程：

Ai studio地址：[飞桨AI Studio - 人工智能学习实训社区 (baidu.com)](https://aistudio.baidu.com/aistudio/index)

![image-20220704132941869](C:\Users\19127\AppData\Roaming\Typora\typora-user-images\image-20220704132941869.png)

使用 Ai studio 的算力需要相应的算力卡，进行登陆注册后可领取”新手礼包“获得算力卡，而且每天使用Ai studio的GPU也会送8小时的算力卡。

在Ai studio上运行项目首先要将数据集(包括项目的全套代码)打包上传：

![image-20220704133449666](C:\Users\19127\AppData\Roaming\Typora\typora-user-images\image-20220704133449666.png)

![image-20220704133512503](C:\Users\19127\AppData\Roaming\Typora\typora-user-images\image-20220704133512503.png)

![image-20220704133711501](C:\Users\19127\AppData\Roaming\Typora\typora-user-images\image-20220704133711501.png

![image-20220704133735350](C:\Users\19127\AppData\Roaming\Typora\typora-user-images\image-20220704133735350.png)

下一步创建项目-->选择类型（Notebook）-->环境配置（Ai studio经典版）-->添加项目描述即可。

创建好项目以后，点击启动环境即可

![image-20220704134121977](C:\Users\19127\AppData\Roaming\Typora\typora-user-images\image-20220704134121977.png)

![image-20220704135723008](C:\Users\19127\AppData\Roaming\Typora\typora-user-images\image-20220704135723008.png)

根据需要选择相应的GPU大小即可，然后进入环境，首先将上传的数据集压缩包解压，数据集放在“data”文件夹下，找到压缩包点右边的三个小点复制解压命令，在终端中运行命令即可。

然后‘cd’,进入解解压后文件夹（也就是在本地打包压缩的文件夹）的目录下，进行模型训练：

模型训练、断点训练、模型评估、模型导出、模型预测有以下相应的命令:

（根据文件目录修改就行，命令结构基本一致）

### 模型训练

```
python tools/train.py -c configs/yolov3/yolov3_darknet53_270e_voc.yml --use_vdl=True --eval
```

### 断点训练

```
python tools/train.py -c configs/yolov3/yolov3_darknet53_270e_voc.yml -r output/yolov3_darknet53_270e_voc/100
```

### 模型评估

```
python tools/eval.py -c configs/yolov3/yolov3_darknet53_270e_voc.yml -o weights=output/yolov3_darknet53_270e_voc/best_model
```

### 模型导出

```
python tools/export_model.py -c configs/yolov3/yolov3_darknet53_270e_voc.yml --output_dir=./inference_model -o weights=output/yolov3_darknet53_270e_voc/best_model
```

### 模型预测

```
python deploy/python/infer.py --model_dir=./inference_model/yolov3_darknet53_270e_voc --image_file=./street.jpg --device=GPU --threshold=0.2
```

### 安装包

```pip install pycocotools lap motmetrics```
